{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1f0b48d",
   "metadata": {},
   "source": [
    "# Make a Churn simulation\n",
    "\n",
    "Make a simulated population, treat none (no marketing to anyone), learn to predict who-churns-most, output a pickle for use in `make_plots`.\n",
    "\n",
    "Churn models don't know anything about marketing - they're built before we test a person's reaction to marketing.\n",
    "\n",
    "* `mkt_neg` (_sleeping dogs_) - marketing is a negative, upon receipt the churn risk increases\n",
    "* `bad_exp` (_lost causes_) - person had a bad experience, they're more likely to churn (regardless of marketing) \n",
    "* `mkt_pos` (_persuadable_) - marketing is a positive, upon receipt the churn risk _decreases_\n",
    "* `brand_loyal` (_sure things_) - person likes the brand, they're less likely to churn (regardless of marketing)\n",
    "\n",
    "Terms taken from \"Identifying who can be saved and who will be driven away by retention activity\", Radcliffe 2007: https://www.stochasticsolutions.com/pdf/SavedAndDrivenAway.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c71ebfb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simpler_mpl import set_common_mpl_styles, set_commas\n",
    "from utility import summarise_groups_pretty, make_ppl, determine_churners\n",
    "from utility import marketing_props, BASE_CHURN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3ba136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\n",
    "TRAIN_SIZE = 100_000\n",
    "# ML\n",
    "TEST_SIZE = 50_000  # 0.3 # 0.3 means 30% test set size\n",
    "\n",
    "# SIZE = 500_000\n",
    "# TEST_SIZE = 100_000\n",
    "VAL_SIZE = TEST_SIZE\n",
    "\n",
    "features = [\"mkt_neg\", \"bad_exp\", \"mkt_pos\", \"brand_loyal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09925e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "determine_churners on 100000 rows with marketing_prop 0.00\n",
      "determine_churners on 50000 rows with marketing_prop 0.00\n",
      "determine_churners on 50000 rows with marketing_prop 1.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19984</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27979</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78548</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84125</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42823</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  \\\n",
       "19984            0        0        0        0        0.16            0   \n",
       "27979            0        0        0        0        0.16            0   \n",
       "78548            1        0        0        0        0.11            0   \n",
       "84125            0        0        0        0        0.16            0   \n",
       "42823            0        0        0        0        0.16            0   \n",
       "\n",
       "       will_churn  \n",
       "19984           0  \n",
       "27979           0  \n",
       "78548           0  \n",
       "84125           0  \n",
       "42823           1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO uplift_test should be 1.0, not 0.999\n",
    "\n",
    "model_type = \"churn\"\n",
    "ppl_train = determine_churners(\n",
    "    make_ppl(TRAIN_SIZE, BASE_CHURN),\n",
    "    marketing_prop=marketing_props[f\"{model_type}_train\"],\n",
    ")\n",
    "ppl_test = determine_churners(\n",
    "    make_ppl(TEST_SIZE, BASE_CHURN),\n",
    "    marketing_prop=marketing_props[f\"{model_type}_test\"],\n",
    ")\n",
    "ppl_val = determine_churners(\n",
    "    make_ppl(VAL_SIZE, BASE_CHURN), marketing_prop=marketing_props[f\"{model_type}_val\"]\n",
    ")\n",
    "\n",
    "X_train = ppl_train[features]\n",
    "X_test = ppl_test[features]\n",
    "X_val = ppl_val[features]\n",
    "y_train = ppl_train[\"will_churn\"]\n",
    "y_test = ppl_test[\"will_churn\"]\n",
    "y_val = ppl_val[\"will_churn\"]\n",
    "\n",
    "ppl = pd.concat((ppl_train, ppl_test))\n",
    "assert ppl.shape[1] == ppl_train.shape[1]\n",
    "\n",
    "ppl.sample(5)  # sample from whole population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e36c3472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob_churn_mean</th>\n",
       "      <th>prob_churn_var</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>90095</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14422</td>\n",
       "      <td>0.160075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>9905</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1113</td>\n",
       "      <td>0.112367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  prob_churn_mean  prob_churn_var  will_churn_sum  \\\n",
       "brand_loyal bad_exp                                                           \n",
       "0           0        90095             0.16             0.0           14422   \n",
       "1           0         9905             0.11             0.0            1113   \n",
       "\n",
       "                     will_churn_mean  \n",
       "brand_loyal bad_exp                   \n",
       "0           0               0.160075  \n",
       "1           0               0.112367  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>100000</td>\n",
       "      <td>0.155048</td>\n",
       "      <td>15535</td>\n",
       "      <td>0.15535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count      prob  will_churn_sum  will_churn_mean\n",
       "mkt_pos mkt_neg                                                   \n",
       "0       0        100000  0.155048           15535          0.15535"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob_churn_mean</th>\n",
       "      <th>prob_churn_var</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>45088</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7160</td>\n",
       "      <td>0.158801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>4912</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>576</td>\n",
       "      <td>0.117264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  prob_churn_mean  prob_churn_var  will_churn_sum  \\\n",
       "brand_loyal bad_exp                                                           \n",
       "0           0        45088             0.16             0.0            7160   \n",
       "1           0         4912             0.11             0.0             576   \n",
       "\n",
       "                     will_churn_mean  \n",
       "brand_loyal bad_exp                   \n",
       "0           0               0.158801  \n",
       "1           0               0.117264  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.155088</td>\n",
       "      <td>7736</td>\n",
       "      <td>0.15472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      prob  will_churn_sum  will_churn_mean\n",
       "mkt_pos mkt_neg                                                  \n",
       "0       0        50000  0.155088            7736          0.15472"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob_churn_mean</th>\n",
       "      <th>prob_churn_var</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>45088</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7234</td>\n",
       "      <td>0.160442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>4912</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552</td>\n",
       "      <td>0.112378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count  prob_churn_mean  prob_churn_var  will_churn_sum  \\\n",
       "brand_loyal bad_exp                                                           \n",
       "0           0        45088             0.16             0.0            7234   \n",
       "1           0         4912             0.11             0.0             552   \n",
       "\n",
       "                     will_churn_mean  \n",
       "brand_loyal bad_exp                   \n",
       "0           0               0.160442  \n",
       "1           0               0.112378  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>prob</th>\n",
       "      <th>will_churn_sum</th>\n",
       "      <th>will_churn_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>50000</td>\n",
       "      <td>0.155088</td>\n",
       "      <td>7786</td>\n",
       "      <td>0.15572</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count      prob  will_churn_sum  will_churn_mean\n",
       "mkt_pos mkt_neg                                                  \n",
       "0       0        50000  0.155088            7786          0.15572"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def ppl_summary(ppl, title):\n",
    "    display(title)\n",
    "    res = ppl.groupby(['brand_loyal', 'bad_exp']).agg(\n",
    "    count=pd.NamedAgg(\"prob_churn\", \"size\"),\n",
    "    prob_churn_mean=pd.NamedAgg(\"prob_churn\", \"mean\"),\n",
    "    prob_churn_var=pd.NamedAgg(\"prob_churn\", \"var\"),\n",
    "    will_churn_sum=pd.NamedAgg(\"will_churn\", \"sum\"),\n",
    "    will_churn_mean=pd.NamedAgg(\"will_churn\", \"mean\"))\n",
    "    display(res)\n",
    "    res = ppl.groupby(['mkt_pos', 'mkt_neg']).agg(\n",
    "    count=pd.NamedAgg(\"prob_churn\", \"size\"),\n",
    "    prob=pd.NamedAgg(\"prob_churn\", \"mean\"),\n",
    "    will_churn_sum=pd.NamedAgg(\"will_churn\", \"sum\"),\n",
    "    will_churn_mean=pd.NamedAgg(\"will_churn\", \"mean\"))\n",
    "    display(res)\n",
    "\n",
    "ppl_summary(ppl_train, \"train\")\n",
    "ppl_summary(ppl_test, \"test\")\n",
    "ppl_summary(ppl_val, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a1e870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "rng.binomial(1, 0.11, 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a09c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX\n",
    "rng = np.random.default_rng(seed=0)\n",
    "ppl_train['will_churn'] = ppl_train['prob_churn'].apply(lambda p: rng.binomial(1, p))\n",
    "ppl_summary(ppl_train, \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e1d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.groupby('brand_loyal')['will_churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf9320",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.groupby('bad_exp')['will_churn'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.groupby(['brand_loyal', 'bad_exp']).agg(\n",
    "    count=pd.NamedAgg(\"will_churn\", \"size\"),\n",
    "    prob=pd.NamedAgg(\"will_churn\", \"mean\"),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f16496",
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = [0.01, 0.05, 0.5, 0.95, 0.99]\n",
    "ppl_train.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_test.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f88518",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl_val.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ffe16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8489b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc nbr and percentage ppl who churn given probability estimates\n",
    "# ppl[\"prob_churn_bin\"] = pd.cut(ppl[\"prob_churn\"], bins=10)\n",
    "# display(ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].sum())\n",
    "# display(\n",
    "#    ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].sum()\n",
    "#    / ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].size()\n",
    "# )\n",
    "# ppl = ppl.drop(columns=\"prob_churn_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4694c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375108f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eef4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that mkt_neg people have a greater prob_churn than non-mkt_neg ppl for a 2 sample ttest\n",
    "\n",
    "# COULD DO\n",
    "# prob_churn and will_churn should be reasonably similar (to 2dp?)\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"bad_exp\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"brand_loyal\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"mkt_neg\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"mkt_pos\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        # gets_mkting should be circa 50%\n",
    "        \"gets_mkting\": pa.Column(\n",
    "            int,\n",
    "            [\n",
    "                pa.Check.isin([0, 1]),\n",
    "                # TODO should check no mkting for train, mkting for test\n",
    "                # pa.Check(lambda s: s.mean() > 0.45),\n",
    "                # pa.Check(lambda s: s.mean() < 0.55),\n",
    "            ],\n",
    "        ),\n",
    "        \"will_churn\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        # prob_churn bounded [0, 1] and if mkt_neg is True then prob_churn should be greater than if mkt_neg if False\n",
    "        \"prob_churn\": pa.Column(\n",
    "            float,\n",
    "            [\n",
    "                pa.Check.le(1.0),\n",
    "                pa.Check.ge(0),\n",
    "                # pa.Hypothesis.two_sample_ttest(\n",
    "                #    sample1=1,\n",
    "                #    sample2=0,\n",
    "                #    groupby=\"mkt_neg\",\n",
    "                #    relationship=\"greater_than\",\n",
    "                #    alpha=0.05,\n",
    "                #    equal_var=True,\n",
    "                # ),\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    strict=True,\n",
    "    ordered=False,\n",
    ")\n",
    "schema.validate(\n",
    "    ppl,\n",
    "    lazy=True,\n",
    ")\n",
    "schema.validate(\n",
    "    ppl_val,\n",
    "    lazy=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064611b6",
   "metadata": {},
   "source": [
    "# Look at some examples of those who do or don't churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de919f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.query(\"will_churn==True and prob_churn > @BASE_CHURN\")[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.query(\"will_churn==False\")[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c9726",
   "metadata": {},
   "source": [
    "# Start to prepare for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b840b4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(set(features)) == len(features), \"Not expecting duplicates\"\n",
    "print(f\"Using: {features}\")\n",
    "\n",
    "# check we've not forgotten any columns as new features\n",
    "non_features = (\n",
    "    set(ppl.columns)\n",
    "    .difference(set(features))\n",
    "    .difference({\"will_churn\", \"prob_churn\", \"gets_mkting\"})\n",
    ")\n",
    "\n",
    "if len(non_features) > 0:\n",
    "    print(f\"IGNORING !!!!!!! {non_features}\")\n",
    "    1 / 0  # we shouldn't get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9518c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ppl_train, ppl_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    ppl, ppl[features], ppl[\"will_churn\"], test_size=TEST_SIZE, shuffle=True\n",
    "# )\n",
    "print(list(x.shape for x in [ppl_train, ppl_test, X_train, X_test, y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a8d6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "est_dummy = DummyClassifier(strategy=\"prior\")\n",
    "est_dummy.fit(X_train, y_train)\n",
    "\n",
    "dummy_proba_pos = est_dummy.predict_proba(X_test)[:, 1]\n",
    "log_loss(y_test, dummy_proba_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf9adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression\n",
    "# base_model = partial(RandomForestClassifier, n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964cc52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_model = base_model\n",
    "# churn_model = LogisticRegression\n",
    "# churn_model = partial(RandomForestClassifier, n_estimators=10)\n",
    "est_churn = churn_model()\n",
    "est_churn.fit(X_train, y_train)\n",
    "print(f\"Fitting churn model with {churn_model}\")\n",
    "\n",
    "y_pred = est_churn.predict_proba(X_test)\n",
    "y_pred_proba_pos = y_pred[:, 1]\n",
    "log_loss(y_test, y_pred_proba_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43617a8",
   "metadata": {},
   "source": [
    "# Gains chart\n",
    "\n",
    "Note if T prob guessed more-wrong than C prob then it is possible for a decreasing gains line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4bfc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del ppl_test, ppl\n",
    "del ppl_train\n",
    "del X_train, X_test\n",
    "del y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d07fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"churn_proba_pos\", \"dummy_proba_pos\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37525c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"y_true\": y_val})\n",
    "\n",
    "result[\"churn_proba_pos\"] = est_churn.predict_proba(X_val)[:, 1]\n",
    "result[\"dummy_proba_pos\"] = est_dummy.predict_proba(X_val)[:, 1]\n",
    "for key in keys:\n",
    "    assert key in result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)\n",
    "fig.suptitle(\"Gains curve - Positive divergence\\nmeans better ordering\")\n",
    "for key in keys:\n",
    "    linestyle = \"-\"\n",
    "    linewidth = 2\n",
    "    if key in {\"up_proba_c\", \"up_proba_t\"}:\n",
    "        linestyle = \"--\"\n",
    "        linewidth = 1\n",
    "\n",
    "    result_sorted = result.sort_values(key, ascending=False).reset_index()\n",
    "    result_sorted[\"y_true_cum\"] = result_sorted[\"y_true\"].cumsum()\n",
    "    result_sorted.plot(\n",
    "        kind=\"line\",\n",
    "        y=\"y_true_cum\",\n",
    "        ax=ax,\n",
    "        label=key,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=linewidth,\n",
    "    )\n",
    "ax.set_ylabel(\"True Positives (faster climb better)\")\n",
    "ax.set_xlabel(\"Validation population\")\n",
    "\n",
    "set_common_mpl_styles(ax, grid_axis=\"both\")\n",
    "# set_commas(ax, True, True)\n",
    "\n",
    "# # zoom on x axis\n",
    "# ax.set_xlim((45_000, result.shape[0]-1));\n",
    "# ax.set_ylim(ymin=6000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09db454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged = pd.merge(\n",
    "    left=result,\n",
    "    right=ppl_val,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "assert test_merged.shape[0] == TEST_SIZE\n",
    "test_merged.sample(10).sort_values(\"prob_churn\").drop(\n",
    "    columns=[] #\"dummy_proba_pos\", \"churn_proba_pos\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_merged[\"churn_proba_pos_bins\"] = pd.cut(test_merged[\"churn_proba_pos\"], 3)\n",
    "#test_merged[\"churn_proba_pos_bins\"] = pd.qcut(test_merged[\"churn_proba_pos\"], 2)\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747a670",
   "metadata": {},
   "source": [
    "# For each row in the test set, group and explain the features\n",
    "\n",
    "If we order the data by predicted use of marketing to increase lift, we can count the underlying features - these should reflect the original distributions.\n",
    "\n",
    "* sure things - have `brand_loyal` and don't respond to marketing, they're likelier to _stay_\n",
    "* lost causes - have `bad_experience` and don't respond to marketing, they're likelier to _leave_\n",
    "* persuadables - have `mkt_pos` as they respond well if marketed to, they're likelier to _stay_ conditional on marketing\n",
    "* sleeping dogs - have `mkt_neg` as they respond negatively if marketed to, they're likelier to _leave_ conditional on marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a785d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_merged.groupby(\"dummy_proba_pos\").agg(\n",
    "    count=pd.NamedAgg(\"mkt_neg\", \"size\"),\n",
    "    prob_churn_if_mktd=pd.NamedAgg(\"will_churn\", \"mean\"),\n",
    "    mkt_pos_sum=pd.NamedAgg(\"mkt_pos\", \"sum\"),\n",
    "    bad_exp_sum=pd.NamedAgg(\"bad_exp\", \"sum\"),\n",
    "    brand_loyal_sum=pd.NamedAgg(\"brand_loyal\", \"sum\"),\n",
    "    mkt_neg_sum=pd.NamedAgg(\"mkt_neg\", \"sum\"),\n",
    ")\n",
    "display(f\"Base churn rate for all is circa {BASE_CHURN*100:0.1f}%\")\n",
    "display(\n",
    "    \"churn_proba_pos_bins is prob(churn), typically we market at the people with highest chance of churn\"\n",
    ")\n",
    "res.style.pipe(summarise_groups_pretty, \"Feature contributions to Churn prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6132d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show bins in equal blocks\n",
    "test_merged2 = test_merged.sort_values('churn_proba_pos_bins').copy()\n",
    "test_merged2 = test_merged2.reset_index(drop=True)\n",
    "test_merged2[\"binned_index\"] = pd.cut(test_merged2.index, 10)\n",
    "\n",
    "res = test_merged2.groupby(\"binned_index\").agg(\n",
    "    count=pd.NamedAgg(\"mkt_neg\", \"size\"),\n",
    "    prob_churn_if_mktd=pd.NamedAgg(\"will_churn\", \"mean\"),\n",
    "    mkt_pos_sum=pd.NamedAgg(\"mkt_pos\", \"sum\"),\n",
    "    bad_exp_sum=pd.NamedAgg(\"bad_exp\", \"sum\"),\n",
    "    brand_loyal_sum=pd.NamedAgg(\"brand_loyal\", \"sum\"),\n",
    "    mkt_neg_sum=pd.NamedAgg(\"mkt_neg\", \"sum\"),\n",
    "    #up_proba_c_mean=pd.NamedAgg(\"up_proba_c\", \"mean\"),\n",
    "    #up_proba_t_mean=pd.NamedAgg(\"up_proba_t\", \"mean\"),\n",
    "    #uplift_diff_t_c=pd.NamedAgg(\"uplift_diff_t_c\", \"mean\")\n",
    ")\n",
    "#res\n",
    "\n",
    "res[::].style.pipe(summarise_groups_pretty, \"Feature contributions to Uplift prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b7315",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_merged.groupby(\"churn_proba_pos_bins\").agg(\n",
    "    count=pd.NamedAgg(\"mkt_neg\", \"size\"),\n",
    "    prob_churn_if_mktd=pd.NamedAgg(\"will_churn\", \"mean\"),\n",
    "    mkt_pos_sum=pd.NamedAgg(\"mkt_pos\", \"sum\"),\n",
    "    bad_exp_sum=pd.NamedAgg(\"bad_exp\", \"sum\"),\n",
    "    brand_loyal_sum=pd.NamedAgg(\"brand_loyal\", \"sum\"),\n",
    "    mkt_neg_sum=pd.NamedAgg(\"mkt_neg\", \"sum\"),\n",
    ")\n",
    "display(f\"Base churn rate for all is circa {BASE_CHURN*100:0.1f}%\")\n",
    "display(\n",
    "    \"churn_proba_pos_bins is prob(churn), typically we market at the people with highest chance of churn\"\n",
    ")\n",
    "res.style.pipe(summarise_groups_pretty, \"Feature contributions to Churn prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b15d6f",
   "metadata": {},
   "source": [
    "# Estimate value to business"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050c40f",
   "metadata": {},
   "source": [
    "## Churn comparison result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89cafee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = test_merged.sort_values('churn_proba_pos', ascending=False).copy() # most likely needing marketing first\n",
    "df_comparison = df_comparison[['churn_proba_pos', 'will_churn']].rename(columns={'will_churn': 'churn_will_churn'})\n",
    "df_comparison = df_comparison.reset_index(drop=True)\n",
    "\n",
    "OUTFILE = \"df_comparison_churn.pickle\"\n",
    "print(f\"Writing to {OUTFILE} with {df_comparison.columns}\")\n",
    "df_comparison.to_pickle(OUTFILE)\n",
    "#f_costing.plot(kind='line', y='value_generated_cumsum');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fbb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = test_merged.sort_values('dummy_proba_pos', ascending=False).copy() # most likely needing marketing first\n",
    "df_comparison = df_comparison[['dummy_proba_pos', 'will_churn']].rename(columns={'will_churn': 'dummy_will_churn'})\n",
    "df_comparison = df_comparison.reset_index(drop=True)\n",
    "\n",
    "OUTFILE = \"df_comparison_dummy.pickle\"\n",
    "print(f\"Writing to {OUTFILE} with {df_comparison.columns}\")\n",
    "df_comparison.to_pickle(OUTFILE)\n",
    "#f_costing.plot(kind='line', y='value_generated_cumsum');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d327b171",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78f0644",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
