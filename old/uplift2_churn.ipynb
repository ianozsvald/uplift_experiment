{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71ebfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandera as pa\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from simpler_mpl import set_common_mpl_styles, set_commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ba136b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population\n",
    "TRAIN_SIZE = 100_000\n",
    "# ML\n",
    "TEST_SIZE = 50_000  # 0.3 # 0.3 means 30% test set size\n",
    "\n",
    "#SIZE = 500_000\n",
    "#TEST_SIZE = 100_000 \n",
    "\n",
    "BASE_CHURN = 0.16  # 16% churn means 84% retention\n",
    "\n",
    "features = [\"mkt_neg\", \"bad_exp\", \"mkt_pos\", \"brand_loyal\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a982418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng.binomial(nbr events e.g. 1 means 0 or 1, p is probability of True, size is nbr of items to generate)\n",
    "\n",
    "# a bad_exp means they had a problem (e.g. bad insurance claim, hard time with mobile phone tech support),\n",
    "# this increases their likelihood of churn\n",
    "# mkt_neg means they really don't like getting marketing and this will increase their likelihood of churn\n",
    "# gets_mkting is a 50/50 split for Treatment (True) or Control (False)\n",
    "\n",
    "def make_ppl(nbr_rows, base_churn, seed=0):\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    ppl = pd.DataFrame(\n",
    "        {\n",
    "            \"brand_loyal\": rng.binomial(1, 0.25, nbr_rows),  # True if they just love to renew\n",
    "            \"bad_exp\": rng.binomial(\n",
    "                1, 0.25, nbr_rows\n",
    "            ),  # True if they had a bad experience with company\n",
    "            \"mkt_neg\": rng.binomial(\n",
    "                1, 0.25, nbr_rows\n",
    "            ),  # True if receiving marketing will increase churn probability for them\n",
    "            \"mkt_pos\": rng.binomial(\n",
    "                1, 0.25, nbr_rows\n",
    "            ),  # True if marketing helps retain this customer\n",
    "        }\n",
    "    )\n",
    "    #ppl[\"prob_churn\"] = BASE_CHURN  # # a reasonably standard churn rate\n",
    "    ppl[\"prob_churn\"] = rng.uniform(base_churn - 0.02, base_churn + 0.02, nbr_rows)\n",
    "    return ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09925e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8506</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.078799</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59369</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.264927</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8557</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43762</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141104</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34388</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144718</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  \\\n",
       "8506             1        0        1        0    0.078799            0   \n",
       "59369            0        1        0        1    0.264927            0   \n",
       "8557             0        0        0        0    0.140344            0   \n",
       "43762            0        0        1        0    0.141104            0   \n",
       "34388            0        0        0        0    0.144718            0   \n",
       "\n",
       "       will_churn  \n",
       "8506            0  \n",
       "59369           1  \n",
       "8557            0  \n",
       "43762           0  \n",
       "34388           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def determine_churners(ppl, marketing_prop, seed=0):\n",
    "    \"\"\"People churn based the marketing_prop==[0.0, 1.0] who receive marketing, \n",
    "    1.0 means all get it, 0 means none, 0.5 means half\"\"\"\n",
    "    ppl = ppl.copy()\n",
    "    rng = np.random.default_rng(seed=0)\n",
    "    nbr_rows = ppl.shape[0]\n",
    "    assert marketing_prop >=0 and marketing_prop <= 1.0, \"Must be [0, 1] as a proportion\"\n",
    "    ppl[\"gets_mkting\"] = rng.binomial(1, marketing_prop, nbr_rows)\n",
    "    # people who like marketing and who get marketing have a lower chance of churning\n",
    "    mask_mkt_pos = (ppl[\"mkt_pos\"] & ppl[\"gets_mkting\"]) == 1  # trues are 1s (ints)\n",
    "    ppl.loc[mask_mkt_pos, \"prob_churn\"] -= 0.1\n",
    "\n",
    "\n",
    "    # people who hate marketing and who get marketing have a higher chance of churning\n",
    "    mask_mkt_neg = (ppl[\"mkt_neg\"] & ppl[\"gets_mkting\"]) == 1  # trues are 1s (ints)\n",
    "    ppl.loc[mask_mkt_neg, \"prob_churn\"] += 0.1  # TODO HUGE BIAS\n",
    "\n",
    "    # people who have had a negative experience have a higher chance of churn\n",
    "    mask_bad_exp = ppl[\"bad_exp\"] == 1\n",
    "    ppl.loc[mask_bad_exp, \"prob_churn\"] += 0.1\n",
    "\n",
    "    # people who like the brand experience have a lower chance of churn\n",
    "    mask_brand_loyal = ppl[\"brand_loyal\"] == 1\n",
    "    ppl.loc[mask_brand_loyal, \"prob_churn\"] -= 0.1\n",
    "\n",
    "    ppl[\"prob_churn\"] = ppl[\"prob_churn\"].clip(lower=0, upper=1)\n",
    "    ppl[\"will_churn\"] = rng.binomial(1, ppl[\"prob_churn\"], ppl.shape[0])\n",
    "    return ppl\n",
    "\n",
    "# TODO uplift_test should be 1.0, not 0.999\n",
    "marketing_props = {'uplift_train': 0.5, 'uplift_test': 0.999, 'churn_train': 0.0, 'churn_test': 1.0}\n",
    "#model_type = 'uplift'\n",
    "model_type = 'churn'\n",
    "ppl_train = determine_churners(make_ppl(TRAIN_SIZE, BASE_CHURN), \n",
    "                               marketing_prop=marketing_props[f\"{model_type}_train\"])\n",
    "\n",
    "ppl_test = determine_churners(make_ppl(TEST_SIZE, BASE_CHURN), marketing_prop=marketing_props[f\"{model_type}_test\"])\n",
    "\n",
    "\n",
    "#ppl_train = make_ppl(TRAIN_SIZE, BASE_CHURN)\n",
    "#ppl_train = determine_churners(ppl_train, marketing_prop=0)\n",
    "\n",
    "#ppl_test = make_ppl(TEST_SIZE, BASE_CHURN)\n",
    "#ppl_test = determine_churners(ppl_test, marketing_prop=1)\n",
    "\n",
    "X_train = ppl_train[features]\n",
    "X_test = ppl_test[features]\n",
    "y_train = ppl_train[\"will_churn\"]\n",
    "y_test = ppl_test[\"will_churn\"]\n",
    "\n",
    "ppl = pd.concat((ppl_train, ppl_test))\n",
    "assert ppl.shape[1] == ppl_train.shape[1]\n",
    "#ppl_train, ppl_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    ppl, ppl[features], ppl[\"will_churn\"], test_size=TEST_SIZE, shuffle=True\n",
    "#)\n",
    "\n",
    "ppl.sample(5) # sample from whole population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64f16496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.249160</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.250310</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>0.159973</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.159860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.432529</td>\n",
       "      <td>0.432145</td>\n",
       "      <td>0.433194</td>\n",
       "      <td>0.434221</td>\n",
       "      <td>0.062295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.366478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042046</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand_loyal        bad_exp        mkt_neg        mkt_pos  \\\n",
       "count  100000.000000  100000.000000  100000.000000  100000.000000   \n",
       "mean        0.249160       0.248500       0.250310       0.252100   \n",
       "std         0.432529       0.432145       0.433194       0.434221   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "1%          0.000000       0.000000       0.000000       0.000000   \n",
       "5%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "95%         1.000000       1.000000       1.000000       1.000000   \n",
       "99%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          prob_churn  gets_mkting     will_churn  \n",
       "count  100000.000000     100000.0  100000.000000  \n",
       "mean        0.159973          0.0       0.159860  \n",
       "std         0.062295          0.0       0.366478  \n",
       "min         0.040002          0.0       0.000000  \n",
       "1%          0.042046          0.0       0.000000  \n",
       "5%          0.050614          0.0       0.000000  \n",
       "50%         0.160029          0.0       0.000000  \n",
       "95%         0.269522          0.0       1.000000  \n",
       "99%         0.277913          0.0       1.000000  \n",
       "max         0.280000          0.0       1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]\n",
    "ppl_train.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8293a6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.251860</td>\n",
       "      <td>0.250460</td>\n",
       "      <td>0.252620</td>\n",
       "      <td>0.249540</td>\n",
       "      <td>0.161512</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.163240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.434086</td>\n",
       "      <td>0.433282</td>\n",
       "      <td>0.434519</td>\n",
       "      <td>0.432751</td>\n",
       "      <td>0.084485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.369588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042410</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159963</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.277412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.369396</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379965</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        brand_loyal       bad_exp       mkt_neg       mkt_pos    prob_churn  \\\n",
       "count  50000.000000  50000.000000  50000.000000  50000.000000  50000.000000   \n",
       "mean       0.251860      0.250460      0.252620      0.249540      0.161512   \n",
       "std        0.434086      0.433282      0.434519      0.432751      0.084485   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "1%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "5%         0.000000      0.000000      0.000000      0.000000      0.042410   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.159963   \n",
       "95%        1.000000      1.000000      1.000000      1.000000      0.277412   \n",
       "99%        1.000000      1.000000      1.000000      1.000000      0.369396   \n",
       "max        1.000000      1.000000      1.000000      1.000000      0.379965   \n",
       "\n",
       "       gets_mkting    will_churn  \n",
       "count      50000.0  50000.000000  \n",
       "mean           1.0      0.163240  \n",
       "std            0.0      0.369588  \n",
       "min            1.0      0.000000  \n",
       "1%             1.0      0.000000  \n",
       "5%             1.0      0.000000  \n",
       "50%            1.0      0.000000  \n",
       "95%            1.0      1.000000  \n",
       "99%            1.0      1.000000  \n",
       "max            1.0      1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl_test.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ffe16f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "      <td>150000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.250060</td>\n",
       "      <td>0.249153</td>\n",
       "      <td>0.251080</td>\n",
       "      <td>0.251247</td>\n",
       "      <td>0.160486</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.160987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.433049</td>\n",
       "      <td>0.432524</td>\n",
       "      <td>0.433636</td>\n",
       "      <td>0.433732</td>\n",
       "      <td>0.070476</td>\n",
       "      <td>0.471406</td>\n",
       "      <td>0.367520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.272448</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346164</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.379965</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         brand_loyal        bad_exp        mkt_neg        mkt_pos  \\\n",
       "count  150000.000000  150000.000000  150000.000000  150000.000000   \n",
       "mean        0.250060       0.249153       0.251080       0.251247   \n",
       "std         0.433049       0.432524       0.433636       0.433732   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "1%          0.000000       0.000000       0.000000       0.000000   \n",
       "5%          0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "95%         1.000000       1.000000       1.000000       1.000000   \n",
       "99%         1.000000       1.000000       1.000000       1.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          prob_churn    gets_mkting     will_churn  \n",
       "count  150000.000000  150000.000000  150000.000000  \n",
       "mean        0.160486       0.333333       0.160987  \n",
       "std         0.070476       0.471406       0.367520  \n",
       "min         0.000000       0.000000       0.000000  \n",
       "1%          0.000000       0.000000       0.000000  \n",
       "5%          0.047455       0.000000       0.000000  \n",
       "50%         0.160014       0.000000       0.000000  \n",
       "95%         0.272448       1.000000       1.000000  \n",
       "99%         0.346164       1.000000       1.000000  \n",
       "max         0.379965       1.000000       1.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.describe(percentiles=percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f8489b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc nbr and percentage ppl who churn given probability estimates\n",
    "#ppl[\"prob_churn_bin\"] = pd.cut(ppl[\"prob_churn\"], bins=10)\n",
    "#display(ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].sum())\n",
    "#display(\n",
    "#    ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].sum()\n",
    "#    / ppl.groupby(\"prob_churn_bin\")[\"will_churn\"].size()\n",
    "#)\n",
    "#ppl = ppl.drop(columns=\"prob_churn_bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4694c494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  will_churn\n",
       "0            0        0        0        1    0.157282            0           0\n",
       "1            0        0        0        1    0.164466            0           0\n",
       "2            0        0        0        0    0.173355            0           0\n",
       "3            0        1        1        0    0.248802            0           0\n",
       "4            1        1        1        0    0.179528            0           1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "375108f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.173355</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.147855</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.269127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.150669</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.360194</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141484</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  \\\n",
       "0                0        0        0        1    0.157282            0   \n",
       "1                0        0        0        1    0.164466            0   \n",
       "2                0        0        0        0    0.173355            0   \n",
       "3                0        1        1        0    0.248802            0   \n",
       "4                1        1        1        0    0.179528            0   \n",
       "...            ...      ...      ...      ...         ...          ...   \n",
       "49995            0        0        1        1    0.147855            1   \n",
       "49996            0        1        0        0    0.269127            1   \n",
       "49997            0        0        0        0    0.150669            1   \n",
       "49998            0        1        1        0    0.360194            1   \n",
       "49999            1        1        0        0    0.141484            1   \n",
       "\n",
       "       will_churn  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               1  \n",
       "...           ...  \n",
       "49995           1  \n",
       "49996           0  \n",
       "49997           0  \n",
       "49998           0  \n",
       "49999           1  \n",
       "\n",
       "[150000 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87eef4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that mkt_neg people have a greater prob_churn than non-mkt_neg ppl for a 2 sample ttest\n",
    "\n",
    "# COULD DO\n",
    "# prob_churn and will_churn should be reasonably similar (to 2dp?)\n",
    "\n",
    "schema = pa.DataFrameSchema(\n",
    "    {\n",
    "        \"bad_exp\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"brand_loyal\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"mkt_neg\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        \"mkt_pos\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        # gets_mkting should be circa 50%\n",
    "        \"gets_mkting\": pa.Column(\n",
    "            int,\n",
    "            [\n",
    "                pa.Check.isin([0, 1]),\n",
    "                # TODO should check no mkting for train, mkting for test\n",
    "                #pa.Check(lambda s: s.mean() > 0.45),\n",
    "                #pa.Check(lambda s: s.mean() < 0.55),\n",
    "            ],\n",
    "        ),\n",
    "        \"will_churn\": pa.Column(int, pa.Check.isin([0, 1])),\n",
    "        # prob_churn bounded [0, 1] and if mkt_neg is True then prob_churn should be greater than if mkt_neg if False\n",
    "        \"prob_churn\": pa.Column(\n",
    "            float,\n",
    "            [\n",
    "                pa.Check.le(1.0),\n",
    "                pa.Check.ge(0),\n",
    "                pa.Hypothesis.two_sample_ttest(\n",
    "                    sample1=1,\n",
    "                    sample2=0,\n",
    "                    groupby=\"mkt_neg\",\n",
    "                    relationship=\"greater_than\",\n",
    "                    alpha=0.05,\n",
    "                    equal_var=True,\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    },\n",
    "    strict=True,\n",
    "    ordered=False,\n",
    ")\n",
    "schema.validate(\n",
    "    ppl,\n",
    "    lazy=True,\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064611b6",
   "metadata": {},
   "source": [
    "# Look at some examples of those who do or don't churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3de919f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.179528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170040</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  will_churn\n",
       "4            1        1        1        0    0.179528            0           1\n",
       "6            0        0        0        0    0.170040            0           1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.query(\"will_churn==True and prob_churn > @BASE_CHURN\")[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4403b4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.157282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.164466</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  gets_mkting  will_churn\n",
       "0            0        0        0        1    0.157282            0           0\n",
       "1            0        0        0        1    0.164466            0           0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.query(\"will_churn==False\")[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3c9726",
   "metadata": {},
   "source": [
    "# Start to prepare for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fabb7079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['brand_loyal', 'bad_exp', 'mkt_neg', 'mkt_pos', 'prob_churn',\n",
       "       'gets_mkting', 'will_churn'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b840b4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: ['mkt_neg', 'bad_exp', 'mkt_pos', 'brand_loyal']\n"
     ]
    }
   ],
   "source": [
    "assert len(set(features)) == len(features), \"Not expecting duplicates\"\n",
    "print(f\"Using: {features}\")\n",
    "\n",
    "# check we've not forgotten any columns as new features\n",
    "non_features = (\n",
    "    set(ppl.columns)\n",
    "    .difference(set(features))\n",
    "    .difference({\"will_churn\", \"prob_churn\", \"gets_mkting\"})\n",
    ")\n",
    "\n",
    "if len(non_features) > 0:\n",
    "    print(f\"IGNORING !!!!!!! {non_features}\")\n",
    "    1 / 0  # we shouldn't get here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9518c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100000, 7), (50000, 7), (100000, 4), (50000, 4), (100000,), (50000,)]\n"
     ]
    }
   ],
   "source": [
    "#ppl_train, ppl_test, X_train, X_test, y_train, y_test = train_test_split(\n",
    "#    ppl, ppl[features], ppl[\"will_churn\"], test_size=TEST_SIZE, shuffle=True\n",
    "#)\n",
    "print(list(x.shape for x in [ppl_train, ppl_test, X_train, X_test, y_train, y_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85a8d6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.44504598751670305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est_dummy = DummyClassifier(strategy=\"prior\")\n",
    "est_dummy.fit(X_train, y_train)\n",
    "\n",
    "dummy_proba_pos = est_dummy.predict_proba(X_test)[:, 1]\n",
    "log_loss(y_test, dummy_proba_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abf9adf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = LogisticRegression\n",
    "#base_model = partial(RandomForestClassifier, n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "964cc52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting churn model with <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4314199275493696"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_model = base_model\n",
    "# churn_model = LogisticRegression\n",
    "# churn_model = partial(RandomForestClassifier, n_estimators=10)\n",
    "est_churn = churn_model()\n",
    "est_churn.fit(X_train, y_train)\n",
    "print(f\"Fitting churn model with {churn_model}\")\n",
    "\n",
    "y_pred = est_churn.predict_proba(X_test)\n",
    "y_pred_proba_pos = y_pred[:, 1]\n",
    "log_loss(y_test, y_pred_proba_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74556717",
   "metadata": {},
   "source": [
    "## Start to prepare for dual fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64f14ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building a C and T model with LogisticRegression() and LogisticRegression()\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m mask_train_t \u001b[38;5;241m=\u001b[39m ppl_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgets_mkting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     15\u001b[0m est_up_c\u001b[38;5;241m.\u001b[39mfit(X_train[mask_train_c], y_train[mask_train_c])\n\u001b[0;32m---> 16\u001b[0m \u001b[43mest_up_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_train_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask_train_t\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# score on their sub-trained population type\u001b[39;00m\n\u001b[1;32m     19\u001b[0m mask_test_c \u001b[38;5;241m=\u001b[39m ppl_test[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgets_mkting\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1508\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1506\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[0;32m-> 1508\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1510\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1513\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1514\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1515\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1516\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my cannot be None\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/sklearn/utils/validation.py:805\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    809\u001b[0m         )\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    812\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "# TODO duplication here will hurt and will make debugging much\n",
    "# harder, this needs simplifying!\n",
    "# higher logloss is worse\n",
    "uplift_model = base_model\n",
    "# uplift_model = LogisticRegression\n",
    "# uplift_model = partial(RandomForestClassifier, n_estimators=10)\n",
    "est_up_c = uplift_model()\n",
    "est_up_t = uplift_model()\n",
    "\n",
    "print(f\"Building a C and T model with {est_up_c} and {est_up_t}\")\n",
    "\n",
    "mask_train_c = ppl_train[\"gets_mkting\"] == 0\n",
    "mask_train_t = ppl_train[\"gets_mkting\"] == 1\n",
    "\n",
    "est_up_c.fit(X_train[mask_train_c], y_train[mask_train_c])\n",
    "est_up_t.fit(X_train[mask_train_t], y_train[mask_train_t])\n",
    "\n",
    "# score on their sub-trained population type\n",
    "mask_test_c = ppl_test[\"gets_mkting\"] == 0\n",
    "mask_test_t = ppl_test[\"gets_mkting\"] == 1\n",
    "up_c_pred_proba_pos = est_up_c.predict_proba(X_test[mask_test_c])[:, 1]\n",
    "up_t_pred_proba_pos = est_up_t.predict_proba(X_test[mask_test_t])[:, 1]\n",
    "\n",
    "print(log_loss(y_test[mask_test_c], up_c_pred_proba_pos))\n",
    "print(\n",
    "    log_loss(y_test[mask_test_t], up_t_pred_proba_pos)\n",
    ")  # CHECK expect lower than control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2945588d",
   "metadata": {},
   "source": [
    "## Check C and T predictions from Uplift model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb59e27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(up_c_pred_proba_pos).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e64ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(up_t_pred_proba_pos).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43617a8",
   "metadata": {},
   "source": [
    "# Gains chart\n",
    "\n",
    "Note if T prob guessed more-wrong than C prob then it is possible for a decreasing gains line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d096e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    # incorrect for uplift! # WRONG\n",
    "    result = pd.DataFrame({\"churn_proba_pos\": y_pred_proba_pos, \"y_true\": y_test})\n",
    "    result[\"dummy_proba_pos\"] = est_dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    result[\"uplift_proba_pos\"] = -1\n",
    "    result.loc[mask_test_t, \"uplift_proba_pos\"] = up_t_pred_proba_pos\n",
    "    result.loc[mask_test_c, \"uplift_proba_pos\"] = up_c_pred_proba_pos\n",
    "    assert (result[\"uplift_proba_pos\"] == -1).sum() == 0, \"No entries for -1 expected\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)\n",
    "    fig.suptitle(\"Gains curve - Positive divergence\\nmeans better ordering\")\n",
    "    keys = [\"uplift_proba_pos\", \"churn_proba_pos\", \"dummy_proba_pos\"]\n",
    "    for key in keys:\n",
    "        result_sorted = result.sort_values(key, ascending=False).reset_index()\n",
    "        result_sorted[\"y_true_cum\"] = result_sorted[\"y_true\"].cumsum()\n",
    "        result_sorted.plot(kind=\"line\", y=\"y_true_cum\", ax=ax, label=key)\n",
    "    ax.set_ylabel(\"True Positives (faster climb better)\")\n",
    "    ax.set_xlabel(\"Test population\")\n",
    "\n",
    "    set_common_mpl_styles(ax, grid_axis=\"both\")\n",
    "    # set_commas(ax, True, True)\n",
    "\n",
    "    # ax.set_xlim((10_000, result.shape[0]-1)); # zoom on x axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e62d121",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# incorrect for uplift!\n",
    "result = pd.DataFrame({\"y_true\": y_test})\n",
    "\n",
    "result[\"churn_proba_pos\"] = est_churn.predict_proba(X_test)[:, 1]\n",
    "result[\"dummy_proba_pos\"] = est_dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)\n",
    "fig.suptitle(\"Gains curve - Positive divergence\\nmeans better ordering\")\n",
    "# key = 'uplift_diff_t_c'\n",
    "keys = ['churn_proba_pos', 'dummy_proba_pos']\n",
    "#keys = [#\"churn_proba_pos\",\n",
    "#    \"uplift_diff_t_c\",\n",
    "#    \"up_proba_c\",\n",
    "#    \"up_proba_t\",\n",
    "#    \"dummy_proba_pos\", \n",
    "#]  # , 'churn_proba_pos']\n",
    "for key in keys:\n",
    "    linestyle = \"-\"\n",
    "    linewidth = 2\n",
    "    if key in {\"up_proba_c\", \"up_proba_t\"}:\n",
    "        linestyle = \"--\"\n",
    "        linewidth = 1\n",
    "    result_sorted = result.sort_values(key, ascending=False).reset_index()\n",
    "    result_sorted[\"y_true_cum\"] = result_sorted[\"y_true\"].cumsum()\n",
    "    result_sorted.plot(\n",
    "        kind=\"line\",\n",
    "        y=\"y_true_cum\",\n",
    "        ax=ax,\n",
    "        label=key,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=linewidth,\n",
    "    )\n",
    "ax.set_ylabel(\"True Positives (faster climb better)\")\n",
    "ax.set_xlabel(\"Test population\")\n",
    "\n",
    "set_common_mpl_styles(ax, grid_axis=\"both\")\n",
    "# set_commas(ax, True, True)\n",
    "\n",
    "# # zoom on x axis\n",
    "# ax.set_xlim((45_000, result.shape[0]-1));\n",
    "# ax.set_ylim(ymin=6000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbddf91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorrect for uplift!\n",
    "result = pd.DataFrame({\"y_true\": y_test})\n",
    "\n",
    "result[\"churn_proba_pos\"] = est_churn.predict_proba(X_test)[:, 1]\n",
    "result[\"dummy_proba_pos\"] = est_dummy.predict_proba(X_test)[:, 1]\n",
    "\n",
    "\n",
    "result[\"up_proba_c\"] = est_up_c.predict_proba(X_test)[:, 1]\n",
    "result[\"up_proba_t\"] = est_up_t.predict_proba(X_test)[:, 1]\n",
    "# if T says 90% prob churn conditional mkting, C says 10% prob churn then +80%\n",
    "# if T says 10% prob churn conditional mkting, C says 90% prob churn then -80%\n",
    "result[\"uplift_diff_t_c\"] = result[\"up_proba_t\"] - result[\"up_proba_c\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), constrained_layout=True)\n",
    "fig.suptitle(\"Gains curve - Positive divergence\\nmeans better ordering\")\n",
    "# key = 'uplift_diff_t_c'\n",
    "# keys = ['uplift_diff_t_c', 'churn_proba_pos', 'dummy_proba_pos']\n",
    "keys = [#\"churn_proba_pos\",\n",
    "    \"uplift_diff_t_c\",\n",
    "    \"up_proba_c\",\n",
    "    \"up_proba_t\",\n",
    "    \"dummy_proba_pos\", \n",
    "]  # , 'churn_proba_pos']\n",
    "for key in keys:\n",
    "    linestyle = \"-\"\n",
    "    linewidth = 2\n",
    "    if key in {\"up_proba_c\", \"up_proba_t\"}:\n",
    "        linestyle = \"--\"\n",
    "        linewidth = 1\n",
    "    result_sorted = result.sort_values(key, ascending=False).reset_index()\n",
    "    result_sorted[\"y_true_cum\"] = result_sorted[\"y_true\"].cumsum()\n",
    "    result_sorted.plot(\n",
    "        kind=\"line\",\n",
    "        y=\"y_true_cum\",\n",
    "        ax=ax,\n",
    "        label=key,\n",
    "        linestyle=linestyle,\n",
    "        linewidth=linewidth,\n",
    "    )\n",
    "ax.set_ylabel(\"True Positives (faster climb better)\")\n",
    "ax.set_xlabel(\"Test population\")\n",
    "\n",
    "set_common_mpl_styles(ax, grid_axis=\"both\")\n",
    "# set_commas(ax, True, True)\n",
    "\n",
    "# # zoom on x axis\n",
    "# ax.set_xlim((45_000, result.shape[0]-1));\n",
    "# ax.set_ylim(ymin=6000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f58055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by predicted uplift, the earliest values have lowest chance of churn if marketed at or are sure things,\n",
    "# the last values have highest chance of churn if marketed at (sleeping dogs) or are lost causes\n",
    "result.sort_values(\"uplift_diff_t_c\", ascending=False)[\"uplift_diff_t_c\"].reset_index(\n",
    "    drop=True\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "09db454f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_true</th>\n",
       "      <th>brand_loyal</th>\n",
       "      <th>bad_exp</th>\n",
       "      <th>mkt_neg</th>\n",
       "      <th>mkt_pos</th>\n",
       "      <th>prob_churn</th>\n",
       "      <th>gets_mkting</th>\n",
       "      <th>will_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37051</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30126</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078042</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3539</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078238</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22704</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.149737</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30924</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.170566</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7435</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.176918</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8570</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241061</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.241575</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.258245</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20495</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.349677</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       y_true  brand_loyal  bad_exp  mkt_neg  mkt_pos  prob_churn  \\\n",
       "37051       0            1        0        0        1    0.000000   \n",
       "30126       0            1        0        1        1    0.078042   \n",
       "3539        0            0        0        0        1    0.078238   \n",
       "22704       0            1        1        0        0    0.149737   \n",
       "30924       0            0        0        0        0    0.170566   \n",
       "7435        0            0        0        0        0    0.176918   \n",
       "8570        0            0        0        1        0    0.241061   \n",
       "49690       0            0        0        1        0    0.241575   \n",
       "36362       0            0        1        1        1    0.258245   \n",
       "20495       1            0        1        1        0    0.349677   \n",
       "\n",
       "       gets_mkting  will_churn  \n",
       "37051            1           0  \n",
       "30126            1           0  \n",
       "3539             1           0  \n",
       "22704            1           0  \n",
       "30924            1           0  \n",
       "7435             1           0  \n",
       "8570             1           0  \n",
       "49690            1           0  \n",
       "36362            1           0  \n",
       "20495            1           1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_merged = pd.merge(\n",
    "    left=result,\n",
    "    right=ppl_test,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    validate=\"one_to_one\",\n",
    ")\n",
    "assert test_merged.shape[0] == TEST_SIZE\n",
    "test_merged.sample(10).sort_values(\"prob_churn\").drop(\n",
    "    columns=[\"dummy_proba_pos\", \"churn_proba_pos\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "399c11a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mkt_neg', 'bad_exp', 'mkt_pos', 'brand_loyal']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_merged[\"uplift_diff_t_c_bins\"] = pd.cut(test_merged[\"uplift_diff_t_c\"], 3)\n",
    "test_merged[\"churn_proba_pos_bins\"] = pd.cut(test_merged[\"churn_proba_pos\"], 3)\n",
    "\n",
    "#test_merged['uplift_diff_t_c_bins'] = pd.qcut(test_merged['uplift_diff_t_c'], 4)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65874898",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'uplift_diff_t_c_bins'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtest_merged\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muplift_diff_t_c_bins\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m      2\u001b[0m     count\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkt_neg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      3\u001b[0m     prob_churn_if_mktd\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill_churn\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     mkt_pos_sum\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkt_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      5\u001b[0m     bad_exp_sum\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbad_exp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      6\u001b[0m     brand_loyal_sum\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbrand_loyal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      7\u001b[0m     mkt_neg_sum\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmkt_neg\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     up_proba_c_mean\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_proba_c\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m     up_proba_t_mean\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mNamedAgg(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mup_proba_t\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     10\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/pandas/core/frame.py:7631\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   7627\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[1;32m   7629\u001b[0m \u001b[38;5;66;03m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[1;32m   7630\u001b[0m \u001b[38;5;66;03m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[0;32m-> 7631\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   7632\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7634\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7637\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7639\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   7640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   7642\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/pandas/core/groupby/groupby.py:889\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 889\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/miniconda3/envs/uplift_experiment/lib/python3.10/site-packages/pandas/core/groupby/grouper.py:862\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    860\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    865\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'uplift_diff_t_c_bins'"
     ]
    }
   ],
   "source": [
    "res = test_merged.groupby(\"uplift_diff_t_c_bins\").agg(\n",
    "    count=pd.NamedAgg(\"mkt_neg\", \"size\"),\n",
    "    prob_churn_if_mktd=pd.NamedAgg(\"will_churn\", \"mean\"),\n",
    "    mkt_pos_sum=pd.NamedAgg(\"mkt_pos\", \"sum\"),\n",
    "    bad_exp_sum=pd.NamedAgg(\"bad_exp\", \"sum\"),\n",
    "    brand_loyal_sum=pd.NamedAgg(\"brand_loyal\", \"sum\"),\n",
    "    mkt_neg_sum=pd.NamedAgg(\"mkt_neg\", \"sum\"),\n",
    "    up_proba_c_mean=pd.NamedAgg(\"up_proba_c\", \"mean\"),\n",
    "    up_proba_t_mean=pd.NamedAgg(\"up_proba_t\", \"mean\"),\n",
    ")\n",
    "#res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b747a670",
   "metadata": {},
   "source": [
    "# For each row in the test set, group and explain the features\n",
    "\n",
    "If we order the data by predicted use of marketing to increase lift, we can count the underlying features - these should reflect the original distributions.\n",
    "\n",
    "* sure things - have `brand_loyal` and don't respond to marketing, they're likelier to _stay_\n",
    "* lost causes - have `bad_experience` and don't respond to marketing, they're likelier to _leave_\n",
    "* persuadables - have `mkt_pos` as they respond well if marketed to, they're likelier to _stay_ conditional on marketing\n",
    "* sleeping dogs - have `mkt_neg` as they respond negatively if marketed to, they're likelier to _leave_ conditional on marketing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d5e31d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Base churn rate for all is circa 16.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m styler\n\u001b[1;32m     10\u001b[0m display(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase churn rate for all is circa \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_CHURN\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m \u001b[43mres\u001b[49m\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39mpipe(make_pretty, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature contributions to Uplift prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "def make_pretty(styler, title):\n",
    "    styler.set_caption(title)\n",
    "    # styler.format(rain_condition)\n",
    "    # styler.format_index(lambda v: v.strftime(\"%A\"))\n",
    "    # styler.background_gradient(axis='columns', vmin=1, vmax=5, cmap=\"YlGnBu\")\n",
    "    styler.background_gradient(axis=\"rows\", cmap=\"YlGnBu\")\n",
    "    return styler\n",
    "\n",
    "\n",
    "display(f\"Base churn rate for all is circa {BASE_CHURN*100:0.1f}%\")\n",
    "res.style.pipe(make_pretty, \"Feature contributions to Uplift prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ac9b7315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Base churn rate for all is circa 16.0%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_83f3f_row0_col0 {\n",
       "  background-color: #e0f3b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_83f3f_row0_col1, #T_83f3f_row1_col3, #T_83f3f_row1_col4, #T_83f3f_row2_col0, #T_83f3f_row2_col2, #T_83f3f_row2_col4, #T_83f3f_row2_col5 {\n",
       "  background-color: #ffffd9;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_83f3f_row0_col2 {\n",
       "  background-color: #e7f6b1;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_83f3f_row0_col3 {\n",
       "  background-color: #9cd8b8;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_83f3f_row0_col4, #T_83f3f_row1_col0, #T_83f3f_row1_col2, #T_83f3f_row1_col5, #T_83f3f_row2_col1, #T_83f3f_row2_col3 {\n",
       "  background-color: #081d58;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_83f3f_row0_col5 {\n",
       "  background-color: #dcf1b2;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_83f3f_row1_col1 {\n",
       "  background-color: #76cabc;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_83f3f_\">\n",
       "  <caption>Feature contributions to Churn prediction</caption>\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th class=\"col_heading level0 col0\" >count</th>\n",
       "      <th class=\"col_heading level0 col1\" >prob_churn_if_mktd</th>\n",
       "      <th class=\"col_heading level0 col2\" >mkt_pos_sum</th>\n",
       "      <th class=\"col_heading level0 col3\" >bad_exp_sum</th>\n",
       "      <th class=\"col_heading level0 col4\" >brand_loyal_sum</th>\n",
       "      <th class=\"col_heading level0 col5\" >mkt_neg_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >churn_proba_pos_bins</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_83f3f_level0_row0\" class=\"row_heading level0 row0\" >(0.0693, 0.138]</th>\n",
       "      <td id=\"T_83f3f_row0_col0\" class=\"data row0 col0\" >12593</td>\n",
       "      <td id=\"T_83f3f_row0_col1\" class=\"data row0 col1\" >0.094259</td>\n",
       "      <td id=\"T_83f3f_row0_col2\" class=\"data row0 col2\" >3080</td>\n",
       "      <td id=\"T_83f3f_row0_col3\" class=\"data row0 col3\" >3090</td>\n",
       "      <td id=\"T_83f3f_row0_col4\" class=\"data row0 col4\" >12593</td>\n",
       "      <td id=\"T_83f3f_row0_col5\" class=\"data row0 col5\" >3214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f3f_level0_row1\" class=\"row_heading level0 row1\" >(0.138, 0.207]</th>\n",
       "      <td id=\"T_83f3f_row1_col0\" class=\"data row1 col0\" >27974</td>\n",
       "      <td id=\"T_83f3f_row1_col1\" class=\"data row1 col1\" >0.160721</td>\n",
       "      <td id=\"T_83f3f_row1_col2\" class=\"data row1 col2\" >6988</td>\n",
       "      <td id=\"T_83f3f_row1_col3\" class=\"data row1 col3\" >0</td>\n",
       "      <td id=\"T_83f3f_row1_col4\" class=\"data row1 col4\" >0</td>\n",
       "      <td id=\"T_83f3f_row1_col5\" class=\"data row1 col5\" >7059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_83f3f_level0_row2\" class=\"row_heading level0 row2\" >(0.207, 0.276]</th>\n",
       "      <td id=\"T_83f3f_row2_col0\" class=\"data row2 col0\" >9433</td>\n",
       "      <td id=\"T_83f3f_row2_col1\" class=\"data row2 col1\" >0.262801</td>\n",
       "      <td id=\"T_83f3f_row2_col2\" class=\"data row2 col2\" >2409</td>\n",
       "      <td id=\"T_83f3f_row2_col3\" class=\"data row2 col3\" >9433</td>\n",
       "      <td id=\"T_83f3f_row2_col4\" class=\"data row2 col4\" >0</td>\n",
       "      <td id=\"T_83f3f_row2_col5\" class=\"data row2 col5\" >2358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f81dabba0b0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = test_merged.groupby(\"churn_proba_pos_bins\").agg(\n",
    "    count=pd.NamedAgg(\"mkt_neg\", \"size\"),\n",
    "    prob_churn_if_mktd=pd.NamedAgg(\"will_churn\", \"mean\"),\n",
    "    mkt_pos_sum=pd.NamedAgg(\"mkt_pos\", \"sum\"),\n",
    "    bad_exp_sum=pd.NamedAgg(\"bad_exp\", \"sum\"),\n",
    "    brand_loyal_sum=pd.NamedAgg(\"brand_loyal\", \"sum\"),\n",
    "    mkt_neg_sum=pd.NamedAgg(\"mkt_neg\", \"sum\"),\n",
    "    #up_proba_c_mean=pd.NamedAgg(\"up_proba_c\", \"mean\"),\n",
    "    #up_proba_t_mean=pd.NamedAgg(\"up_proba_t\", \"mean\"),\n",
    ")\n",
    "display(f\"Base churn rate for all is circa {BASE_CHURN*100:0.1f}%\")\n",
    "res.style.pipe(make_pretty, \"Feature contributions to Churn prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b15d6f",
   "metadata": {},
   "source": [
    "# Estimate value to business by using Uplift over Churn\n",
    "\n",
    "**caveat** this assume we know who we will and won't market to - but that's goverened by the earlier simulation! This needs to be **figured out**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19ab6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETENTION_VALUE = 100\n",
    "MARKETING_VALUE = -100 # negative means a cost\n",
    "\n",
    "test_merged_value = test_merged.copy()\n",
    "\n",
    "test_merged_value['cust_value'] = test_merged_value['gets_mkting'] * MARKETING_VALUE + (1-test_merged_value['will_churn']) * RETENTION_VALUE\n",
    "churn_cum_sum = test_merged_value.sort_values('churn_proba_pos', ascending=False)['cust_value'].cumsum().reset_index(drop=True)\n",
    "#churn_cum_sum.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "uplift_cum_sum = test_merged_value.sort_values('uplift_diff_t_c', ascending=False)['cust_value'].cumsum().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1a34da",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'churn_cum_sum': churn_cum_sum, 'uplift_cum_sum': uplift_cum_sum}).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5144f87a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
